{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZpoIAeweWxk"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh1w_OplY1-t",
        "outputId": "fa3c96cc-6867-4c66-b266-f8d1dc091bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/peabody124/GaitTransformer\n",
            "  Cloning https://github.com/peabody124/GaitTransformer to /tmp/pip-req-build-300iole6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/peabody124/GaitTransformer /tmp/pip-req-build-300iole6\n",
            "  Resolved https://github.com/peabody124/GaitTransformer to commit 215cec8178318a9aaa081afe23b65e6cc4132976\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from gait_transformer==0.0.1) (0.4.26)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gait_transformer==0.0.1) (1.25.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from gait_transformer==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->gait_transformer==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->gait_transformer==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->gait_transformer==0.0.1) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gait_transformer==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->gait_transformer==0.0.1) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->gait_transformer==0.0.1) (3.2.2)\n",
            "Building wheels for collected packages: gait_transformer\n",
            "  Building wheel for gait_transformer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gait_transformer: filename=gait_transformer-0.0.1-py2.py3-none-any.whl size=6343109 sha256=d02d9ca35f13c95c697606256ef9e4c16731a77c7c2d72a8c788783f76a6ef7b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_ymvp63u/wheels/dc/d7/bb/93893f9de448cd2ecf44c26d72890541125c4f88a747210c4d\n",
            "Successfully built gait_transformer\n",
            "Installing collected packages: gait_transformer\n",
            "Successfully installed gait_transformer-0.0.1\n",
            "Cloning into 'BodyModels'...\n",
            "remote: Enumerating objects: 1505, done.\u001b[K\n",
            "remote: Counting objects: 100% (1505/1505), done.\u001b[K\n",
            "remote: Compressing objects: 100% (690/690), done.\u001b[K\n",
            "remote: Total 1505 (delta 992), reused 1316 (delta 804), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1505/1505), 30.57 MiB | 11.51 MiB/s, done.\n",
            "Resolving deltas: 100% (992/992), done.\n",
            "/content/BodyModels\n",
            "Processing /content/BodyModels\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from body_models==0.1.0)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting equinox (from body_models==0.1.0)\n",
            "  Downloading equinox-0.11.4-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.2/175.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (0.4.26)\n",
            "Collecting jaxlie (from body_models==0.1.0)\n",
            "  Downloading jaxlie-1.4.1-py3-none-any.whl (22 kB)\n",
            "Collecting jmp (from body_models==0.1.0)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Collecting mujoco-mjx (from body_models==0.1.0)\n",
            "  Downloading mujoco_mjx-3.1.6-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (1.11.4)\n",
            "Requirement already satisfied: tensorflow_probability[jax] in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (0.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from body_models==0.1.0) (4.66.4)\n",
            "Collecting jaxtyping>=0.2.20 (from equinox->body_models==0.1.0)\n",
            "  Downloading jaxtyping-0.2.29-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from equinox->body_models==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->body_models==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->body_models==0.1.0) (3.3.0)\n",
            "Collecting jax-dataclasses>=1.4.4 (from jaxlie->body_models==0.1.0)\n",
            "  Downloading jax_dataclasses-1.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting tyro (from jaxlie->body_models==0.1.0)\n",
            "  Downloading tyro-0.8.4-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco-mjx->body_models==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco-mjx->body_models==0.1.0) (1.7.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mujoco-mjx->body_models==0.1.0) (0.4.26+cuda12.cudnn89)\n",
            "Collecting mujoco>=3.1.6.dev0 (from mujoco-mjx->body_models==0.1.0)\n",
            "  Downloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh (from mujoco-mjx->body_models==0.1.0)\n",
            "  Downloading trimesh-4.4.0-py3-none-any.whl (694 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.6/694.6 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->body_models==0.1.0) (0.1.86)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability[jax]->body_models==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability[jax]->body_models==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability[jax]->body_models==0.1.0) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability[jax]->body_models==0.1.0) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability[jax]->body_models==0.1.0) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->body_models==0.1.0) (0.12.1)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.20->equinox->body_models==0.1.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting glfw (from mujoco>=3.1.6.dev0->mujoco-mjx->body_models==0.1.0)\n",
            "  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=3.1.6.dev0->mujoco-mjx->body_models==0.1.0) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco-mjx->body_models==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco-mjx->body_models==0.1.0) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco-mjx->body_models==0.1.0) (3.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->jaxlie->body_models==0.1.0) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->jaxlie->body_models==0.1.0) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro->jaxlie->body_models==0.1.0)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->jaxlie->body_models==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->jaxlie->body_models==0.1.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->jaxlie->body_models==0.1.0) (0.1.2)\n",
            "Building wheels for collected packages: body_models\n",
            "  Building wheel for body_models (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for body_models: filename=body_models-0.1.0-py3-none-any.whl size=1434834 sha256=415b61cfd489a9f3418c5d2ceff1e36715597f99f5283c9efca3f0ef648436cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w8tzgdqc/wheels/38/3b/98/c17d4d098f46295204c0ee6db27c1b2ea00ad479a23ee44038\n",
            "Successfully built body_models\n",
            "Installing collected packages: glfw, typeguard, trimesh, shtab, jmp, einops, jaxtyping, tyro, mujoco, jax-dataclasses, equinox, mujoco-mjx, jaxlie, body_models\n",
            "Successfully installed body_models-0.1.0 einops-0.8.0 equinox-0.11.4 glfw-2.7.0 jax-dataclasses-1.6.0 jaxlie-1.4.1 jaxtyping-0.2.29 jmp-0.0.4 mujoco-3.1.6 mujoco-mjx-3.1.6 shtab-1.7.1 trimesh-4.4.0 typeguard-2.13.3 tyro-0.8.4\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/peabody124/GaitTransformer\n",
        "!git clone https://peabody124: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@github.com/peabody124/BodyModels.git\n",
        "\n",
        "%cd BodyModels\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=5\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGOlpC7OaHBN",
        "outputId": "fd935783-b785-4498-8f4a-a75744a8a893"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-06 01:27:17.986245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749173238.059879  491427 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749173238.085051  491427 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749173238.150852  491427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749173238.150913  491427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749173238.150921  491427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749173238.150928  491427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-06 01:27:18.171148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: MUJOCO_GL=egl\n",
            "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
            "TensorFlow is using the GPU\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1749173250.057938  491427 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44842 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 JAX devices:\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# limit jax and TF from consuming all GPU memory\n",
        "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow is using the GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow is not using the GPU\")\n",
        "\n",
        "\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# Check for available GPU devices\n",
        "num_devices = jax.local_device_count()\n",
        "print(f\"Found {num_devices} JAX devices:\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OKkgil4DaJvE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qBPlANaFcC0m"
      },
      "outputs": [],
      "source": [
        "# test the body model loads\n",
        "from body_models.biomechanics_mjx.forward_kinematics import ForwardKinematics\n",
        "\n",
        "fk = ForwardKinematics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhtjaa_celBE"
      },
      "source": [
        "# Run MeTAbs-ACAE on the video\n",
        "\n",
        "First upload a video to your colab environment and then select it with the next cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYVDlb5pH59",
        "outputId": "4a5ef7f1-10cd-4553-dbb1-2905980b033c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMG_2192_boxes.npz\t   IMG_4680_fitted_model.npz\n",
            "IMG_2192_confs.npz\t   IMG_4680_keypoints.npz\n",
            "IMG_2192_fitted_model.npz  IMG_4680_mjx.mp4\n",
            "IMG_2192_keypoints.npz\t   PXL_20250223_155039732_fitted_model.npz\n",
            "IMG_2192_keypoints2d.npz   PXL_20250223_155039732_keypoints.npz\n",
            "IMG_2192_keypoints3d.npz   README.md\n",
            "IMG_2193_boxes.npz\t   __pycache__\n",
            "IMG_2193_confs.npz\t   floss.MOV\n",
            "IMG_2193_fitted_model.npz  humanoid\n",
            "IMG_2193_keypoints.npz\t   main.py\n",
            "IMG_2193_keypoints2d.npz   monocular-demo.ipynb\n",
            "IMG_2193_keypoints3d.npz   pyproject.toml\n",
            "IMG_4678_fitted_model.npz  utils.py\n",
            "IMG_4678_keypoints.npz\t   uv.lock\n",
            "IMG_4678_mjx.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid, fd = os.forkpty()\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "FjZULo2fZUjX",
        "outputId": "3664ef34-29c2-4724-f0fd-e46175e40e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available files:\n",
            "1. floss.MOV\n",
            "2. IMG_4678_mjx.mp4\n",
            "3. IMG_4680_mjx.mp4\n",
            "You selected: floss.MOV\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List files in current directory\n",
        "files = os.listdir()\n",
        "files = [f for f in files if 'mp4' in f or 'MOV' in f]\n",
        "\n",
        "if len(files) > 1:\n",
        "    print(\"Available files:\")\n",
        "    for i, file in enumerate(files):\n",
        "        print(f\"{i+1}. {file}\")\n",
        "\n",
        "    # Prompt user for selection\n",
        "    choice = int(input(\"Enter the number of the file to select: \")) - 1\n",
        "    video_filepath = files[choice]\n",
        "\n",
        "    print(f\"You selected: {video_filepath}\")\n",
        "\n",
        "else:\n",
        "\n",
        "    assert len(files) == 1, \"No videos uploaded\"\n",
        "\n",
        "    video_filepath = files[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvqnF3dNaCjU"
      },
      "outputs": [],
      "source": [
        "model = hub.load('https://bit.ly/metrabs_l')  # Takes about 3 minutes\n",
        "\n",
        "# there are many skeleton formats support by this model. we are selecting one\n",
        "# compatible with the gait transformer we will use below\n",
        "skeleton = 'bml_movi_87'\n",
        "\n",
        "# get the joint names and the edges between them for visualization below\n",
        "joint_names = model.per_skeleton_joint_names[skeleton].numpy().astype(str)\n",
        "joint_edges = model.per_skeleton_joint_edges[skeleton].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEQooGDeacyB"
      },
      "outputs": [],
      "source": [
        "from gait_transformer.util import video_reader\n",
        "from tqdm import tqdm\n",
        "\n",
        "vid = video_reader(video_filepath)\n",
        "\n",
        "accumulated = None\n",
        "for i, frame_batch in tqdm(enumerate(vid)):\n",
        "    pred = model.detect_poses_batched(frame_batch, skeleton=skeleton)\n",
        "\n",
        "    if accumulated is None:\n",
        "        accumulated = pred\n",
        "\n",
        "    else:\n",
        "        # concatenate the ragged tensor along the batch for each element in the dictionary\n",
        "        for key in accumulated.keys():\n",
        "            accumulated[key] = tf.concat([accumulated[key], pred[key]], axis=0)\n",
        "\n",
        "    # if i > 10:\n",
        "    #     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPFb5gPbm-mg"
      },
      "outputs": [],
      "source": [
        "num_people = [p.shape[0] for p in accumulated['poses2d']]\n",
        "\n",
        "# assert this is 1 for all the frames\n",
        "assert len(set(num_people)) == 1\n",
        "\n",
        "# then extract the information for that person\n",
        "boxes = np.array([p[0] for p in accumulated['boxes']])\n",
        "pose3d = np.array([p[0] for p in accumulated['poses3d']])\n",
        "pose2d = np.array([p[0] for p in accumulated['poses2d']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS3RX2mMY_dm"
      },
      "outputs": [],
      "source": [
        "# For convenience, save the keypoints in case the notebook crashes or you have to restart\n",
        "\n",
        "pose3d = np.array([p[0] for p in accumulated['poses3d']])\n",
        "\n",
        "with open('keypoints3d.npz', 'wb') as f:\n",
        "    np.savez(f, pose3d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCDNvA_G7XW5"
      },
      "source": [
        "# Exploration step: try to extract the knee angle over time\n",
        "\n",
        "Example approach: take the cross product between limb segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pn0np4Q8JdO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_6UMGLB8KDe"
      },
      "source": [
        "# Now compute kinematics end-to-end using a differentiable body model\n",
        "\n",
        "This uses an implicit representation $f_\\theta: t \\rightarrow \\theta \\in \\mathbb R^{40}$, which is then passed through the forward kinematic model to get the predicted 3D keypoints: $\\mathcal M_\\beta: \\theta \\rightarrow \\mathbf y \\in \\mathbb R^{87 \\times 3}$.\n",
        "\n",
        "We optimize the difference between the predicted 3D keypoints and the detected 3D keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MikOk2_B7nWV"
      },
      "outputs": [],
      "source": [
        "with open('keypoints3d.npz', 'rb') as f:\n",
        "    keypoints3d = np.load(f, allow_pickle=True)['arr_0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf_AVjhVk5Tp"
      },
      "outputs": [],
      "source": [
        "from jax import numpy as jnp\n",
        "\n",
        "timestamps = jnp.arange(len(pose3d)) / 30.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGSE5_IEoavG"
      },
      "outputs": [],
      "source": [
        "from jaxtyping import Integer, Float, Array, PRNGKeyArray\n",
        "from typing import Tuple, Dict\n",
        "from tqdm import trange\n",
        "import equinox as eqx\n",
        "import optax\n",
        "\n",
        "from body_models.biomechanics_mjx.kinetic_trajectory import KineticsWrapper, get_default_wrapper\n",
        "\n",
        "# construct a loss function between the forward pass through the forward kinematic\n",
        "# implicit representation and the resulting keypoint and the detected keypoitns\n",
        "\n",
        "def loss(\n",
        "    model: KineticsWrapper,\n",
        "    x: Float[Array, \"times\"],\n",
        "    y: Float[Array, \"times keypoints 3\"],\n",
        "    site_offset_regularization = 1e-1\n",
        ") -> Tuple[Float, Dict]:\n",
        "\n",
        "    timestamps = x\n",
        "    keypoints3d = y\n",
        "    metrics = {}\n",
        "\n",
        "    # NOTE: steps is an make sure this retraces for different dimensions\n",
        "    (state, constraints, next_states), (ang, vel, action) = model(\n",
        "        timestamps,\n",
        "        skip_vel=True,\n",
        "        skip_action=True,\n",
        "    )\n",
        "\n",
        "    pred_kp3d = state.site_xpos\n",
        "\n",
        "    l = jnp.mean((pred_kp3d - keypoints3d) ** 2)\n",
        "    metrics[\"kp_err\"] = l\n",
        "\n",
        "    # regularize marker offset\n",
        "    l_site_offset = jnp.sum(jnp.square(model.site_offsets))\n",
        "    l += l_site_offset * site_offset_regularization\n",
        "\n",
        "    # make loss the first key in the dictionary by popping and building a new dictionary with the rest\n",
        "    metrics = {\"loss\": l, **metrics}\n",
        "\n",
        "    return l, metrics\n",
        "\n",
        "\n",
        "@eqx.filter_jit\n",
        "def step(model, opt_state, data, loss_grad, optimizer, **kwargs):\n",
        "    x, targets = data\n",
        "\n",
        "    (val, metrics), grads = loss_grad(model, x=x, y=targets, **kwargs)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state, model)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    return val, model, opt_state, metrics\n",
        "\n",
        "\n",
        "def fit_model(\n",
        "    model: KineticsWrapper,\n",
        "    dataset: Tuple,\n",
        "    lr_end_value: float = 1e-8,\n",
        "    lr_init_value: float = 1e-4,\n",
        "    max_iters: int = 5000,\n",
        "    clip_by_global_norm: float = 0.1,\n",
        "):\n",
        "\n",
        "    # work out the transition steps to make the desired schedule\n",
        "    transition_steps = 10\n",
        "    lr_decay_rate = (lr_end_value / lr_init_value) ** (1.0 / (max_iters // transition_steps))\n",
        "    learning_rate = optax.warmup_exponential_decay_schedule(\n",
        "        init_value=0,\n",
        "        warmup_steps=0,\n",
        "        peak_value=lr_init_value,\n",
        "        end_value=lr_end_value,\n",
        "        decay_rate=lr_decay_rate,\n",
        "        transition_steps=transition_steps,\n",
        "    )\n",
        "\n",
        "    optimizer = optax.chain(\n",
        "        optax.adamw(learning_rate=learning_rate, b1=0.8, weight_decay=1e-5), optax.zero_nans(), optax.clip_by_global_norm(clip_by_global_norm)\n",
        "    )\n",
        "    opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
        "\n",
        "    loss_grad = eqx.filter_value_and_grad(loss, has_aux=True)\n",
        "\n",
        "    counter = trange(max_iters)\n",
        "    for i in counter:\n",
        "\n",
        "        val, model, opt_state, metrics = step(model, opt_state, dataset, loss_grad, optimizer)\n",
        "\n",
        "        if i > 0 and i % int(max_iters // 10) == 0:\n",
        "            print(f\"iter: {i} loss: {val}.\")  # metrics: {metrics}\")\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            metrics = {k: v.item() for k,v in metrics.items()}\n",
        "            print(val, metrics)\n",
        "\n",
        "    return model, metrics\n",
        "\n",
        "# convert pose to m\n",
        "pose3d = np.array([p[0] for p in accumulated['poses3d']])\n",
        "pose = pose3d\n",
        "pose = pose[:, :, [0, 2, 1]]\n",
        "pose[:, :, 2] *= -1\n",
        "pose /= 1000.0\n",
        "\n",
        "pose = pose - np.min(pose, axis=1, keepdims=True)\n",
        "\n",
        "dataset = (timestamps, pose)\n",
        "\n",
        "fkw = get_default_wrapper()\n",
        "updated_model, metrics = fit_model(fkw, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMQJ_t3X85zm"
      },
      "source": [
        "# Now explore the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpVUeeWwF9Az"
      },
      "outputs": [],
      "source": [
        "(state, constraints, next_states), (ang, vel, action) = updated_model(dataset[0], skip_vel=True, skip_action=True)\n",
        "jnp.mean((state.site_xpos.shape - dataset[1]) ** 2)\n",
        "\n",
        "# plot the knees\n",
        "plt.figure()\n",
        "plt.plot(ang[:, [9, 16]]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8bkECg8zSZw"
      },
      "outputs": [],
      "source": [
        "from body_models.biomechanics_mjx.visualize import render_trajectory, jupyter_embed_video\n",
        "\n",
        "fn = 'reconstruction.mp4'\n",
        "render_trajectory(ang, fn, xml_path=None)\n",
        "HTML = jupyter_embed_video(fn)\n",
        "HTML"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IZpoIAeweWxk"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
